@misc{Chang2016,
abstract = {Libsvm is a simple, easy-to-use, and efficient software for SVM classification and regression. It solves C-SVM classification, nu-SVM classification, one-class-SVM, epsilon-SVM regression, and nu-SVM regression. It also provides an automatic model selection tool for C-SVM classification. This document explains the use of libsvm.},
author = {Chang, Chih-Chung and Lin, Chih-Jen},
title = {libsvm},
url = {https://github.com/cjlin1/libsvm},
urldate = {2017-10-10},
year = {2016}
}
@article{Manning2014,
abstract = {We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural language analysis. This toolkit is quite widely used, both in the research NLP community and also among commercial and government users of open source NLP technology. We suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage.},
annote = {CoreNLP},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Manning, Christopher and Surdeanu, Mihai and Bauer, John and Finkel, Jenny and Bethard, Steven and McClosky, David},
doi = {10.3115/v1/P14-5010},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/StanfordCoreNlp2014.pdf:pdf},
isbn = {9781941643006},
issn = {1098-6596},
journal = {Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
pages = {55--60},
pmid = {25246403},
title = {{The Stanford CoreNLP Natural Language Processing Toolkit}},
url = {http://aclweb.org/anthology/P14-5010},
year = {2014}
}
@article{Hristidis2003,
abstract = {Applications in which plain text coexists with structured data are$\backslash$npervasive. Commercial relational database management systems (RDBMSs)$\backslash$ngenerally provide querying capabilities for text attributes that$\backslash$nincorporate state-of-the-art information retrieval (IR) relevance$\backslash$nranking strategies, but this search functionality requires that queries$\backslash$nspecify the exact column or columns against which a given list of$\backslash$nkeywords is to be matched. This requirement can be cumbersome and$\backslash$ninflexible from a user perspective: good answers to a keyword query$\backslash$nmight need to be "assembled" -in perhaps unforeseen ways- by joining$\backslash$ntuples from multiple relations. This observation has motivated recent$\backslash$nresearch on free-form keyword search over RDBMSs. In this paper,$\backslash$nwe adapt IR-style document-relevance ranking strategies to the problem$\backslash$nof processing free-form keyword queries over RDBMSs. Our query model$\backslash$ncan handle queries with both AND and OR semantics, and exploits the$\backslash$nsophisticated single-column text-search functionality often available$\backslash$nin commercial RDBMSs. We develop query-processing strategies that$\backslash$nbuild on a crucial characteristic of IR-style keyword search: only$\backslash$nthe few most relevant matches -according to some definition of "relevance"-$\backslash$nare generally of interest. Consequently, rather than computing all$\backslash$nmatches for a keyword query, which leads to inefficient executions,$\backslash$nour techniques focus on the top-k matches for the query, for moderate$\backslash$nvalues of k. A thorough experimental evaluation over real data shows$\backslash$nthe performance advantages of our approach.},
author = {Hristidis, Vagelis and Gravano, Luis and Papakonstantinou, Yannis},
doi = {DOI: 10.1016/B978-012722442-8/50080-X},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/Efficient IR-Style Keyword Search.pdf:pdf},
isbn = {0-12-722442-4},
journal = {Vldb},
keywords = {assembled,be,by joining tuples,free-form keyword,from multiple relations,in perhaps unforeseen ways,motivated recent research on,query might need to,this observation has},
pages = {850--861},
title = {{Efficient IR-style keyword search over relational databases}},
url = {http://dl.acm.org/citation.cfm?id=1315451.1315524},
year = {2003}
}
@article{Agrawal2002,
abstract = {Internet search engines have popularized the keyword-based search paradigm. While traditional database management systems offer powerful query languages, they do not allow keyword-based search. In this paper, we discuss DBXplorer, a system that enables keyword-based search in relational databases. DBXplorer has been implemented using a commercial relational database and web server and allows users to interact via a browser front-end. We outline the challenges and discuss the implementation of our system including results of extensive experimental evaluation.},
annote = {probs not that useful},
author = {Agrawal, Sanjay and Chaudhuri, Surajit and Das, Gautam},
doi = {10.1109/ICDE.2002.994693},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/DBXplorer.pdf:pdf},
isbn = {0-7695-1531-2},
issn = {10844627},
journal = {Proceedings - International Conference on Data Engineering},
keywords = {a matching row may,by,database design,e,for,g,joining several tables on,need to be obtained,needs to be leveraged,on,secondly,the availability of indexes,the fly,the physical,various database columns},
pages = {5--16},
title = {{DBXplorer: A system for keyword-based search over relational databases}},
year = {2002}
}
@article{Page1998,
abstract = {The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said objectively about the relative importance of Web pages. This paper describes PageRank, a method for rating Web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random Web surfer. We show how to efficiently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation.},
annote = {Why pagerank doesnt fit my project},
archivePrefix = {arXiv},
arxivId = {1111.4503v1},
author = {Page, Lawrence and Brin, Sergey and Motwani, Rajeev and Winograd, Terry},
doi = {10.1.1.31.1768},
eprint = {1111.4503v1},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/1999-PageRank.pdf:pdf},
isbn = {9781424433803},
issn = {1752-0509},
journal = {World Wide Web Internet And Web Information Systems},
number = {1999-66},
pages = {1--17},
pmid = {20840727},
title = {{The PageRank Citation Ranking: Bringing Order to the Web}},
url = {http://ilpubs.stanford.edu:8090/422},
volume = {54},
year = {1998}
}
@article{Goodman1996,
abstract = {Many different metrics exist for evaluating parsing results, including Viterbi, Crossing Brackets Rate, Zero Crossing Brackets Rate, and several others. However, most parsing algorithms, including the Viterbi algorithm, attempt to optimize the same metric, namely the probability of getting the correct labelled tree. By choosing a parsing algorithm appropriate for the evaluation metric, better performance can be achieved. We present two new algorithms: the ``Labelled Recall Algorithm,'' which maximizes the expected Labelled Recall Rate, and the ``Bracketed Recall Algorithm,'' which maximizes the Bracketed Recall Rate. Experimental results are given, showing that the two new algorithms have improved performance over the Viterbi algorithm on many criteria, especially the ones that they optimize.},
archivePrefix = {arXiv},
arxivId = {cmp-lg/9605036},
author = {Goodman, Joshua},
doi = {10.3115/981863.981887},
eprint = {9605036},
file = {:C$\backslash$:/Users/Tom/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodman - 1996 - Parsing Algorithms and Metrics.pdf:pdf},
journal = {ReCALL},
number = {June},
pages = {177--183},
primaryClass = {cmp-lg},
title = {{Parsing Algorithms and Metrics}},
url = {http://arxiv.org/abs/cmp-lg/9605036},
year = {1996}
}
@article{Nayak2015,
abstract = {Word embeddings have shown promise in a range of NLP tasks; however, it is currently difficult to accurately encode categorical lexical relations in these vector spaces. We consider one such important relation – hypernymy – and investigate the feasibility of learning a function in vector space to capture it. We argue that hy-pernymy is significantly harder to capture than the analogy tasks word embeddings are traditionally evaluated on. We show that a simple neural network outperforms previous systems at classifying hypernymy, and present experiments for learning a function to predict the hypernym of a word in a vector space.},
annote = {good point about why word2vec may not be good for hyponym extraction - words have multiple meanings!},
author = {Nayak, Neha},
doi = {10.3115/v1/P14-1113},
file = {:C$\backslash$:/Users/Tom/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nayak - 2015 - Learning Hypernymy over Word Embeddings.pdf:pdf},
journal = {CS224N Projects},
pages = {1--8},
title = {{Learning Hypernymy over Word Embeddings}},
year = {2015}
}
@misc{Manning2012,
author = {Manning, Christopher and Jurafsky, Daniel},
title = {{Using Patterns to Extract Relations}},
url = {https://www.youtube.com/watch?v=VodeEgvxgtA},
year = {2012}
}
@article{Mikolov2013,
abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
archivePrefix = {arXiv},
arxivId = {1301.3781},
author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
doi = {10.1162/153244303322533223},
eprint = {1301.3781},
file = {:C$\backslash$:/Users/Tom/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Vector Space.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
pages = {1--12},
pmid = {18244602},
title = {{Efficient Estimation of Word Representations in Vector Space}},
url = {http://arxiv.org/abs/1301.3781},
year = {2013}
}
@article{Goldberg2014,
abstract = {The word2vec software of Tomas Mikolov and colleagues (https://code.google.com/p/word2vec/ ) has gained a lot of traction lately, and provides state-of-the-art word embeddings. The learning models behind the software are described in two research papers. We found the description of the models in these papers to be somewhat cryptic and hard to follow. While the motivations and presentation may be obvious to the neural-networks language-modeling crowd, we had to struggle quite a bit to figure out the rationale behind the equations. This note is an attempt to explain equation (4) (negative sampling) in "Distributed Representations of Words and Phrases and their Compositionality" by Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado and Jeffrey Dean.},
archivePrefix = {arXiv},
arxivId = {1402.3722},
author = {Goldberg, Yoav and Levy, Omer},
doi = {10.1162/jmlr.2003.3.4-5.951},
eprint = {1402.3722},
file = {:C$\backslash$:/Users/Tom/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goldberg, Levy - 2014 - word2vec Explained deriving Mikolov et al.'s negative-sampling word-embedding method.pdf:pdf},
isbn = {2150-8097},
issn = {0003-6951},
number = {2},
pages = {1--5},
pmid = {903},
title = {{word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method}},
url = {http://arxiv.org/abs/1402.3722},
year = {2014}
}
@misc{Manning2012a,
author = {Manning, Christopher and Jurafsky, Daniel},
title = {{Using Patterns to Extract Relations}},
url = {https://www.youtube.com/watch?v=VodeEgvxgtA},
year = {2012}
}
@article{Zhang2008,
abstract = {Keywords are subset of words or phrases from a document that can describe the meaning of the document. Many text mining applications can take advantage from it. Unfortunately, a large portion of documents still do not have keywords assigned. On the other hand, manual assignment of high quality keywords is expensive, time-consuming, and error prone. Therefore, most algorithms and systems aimed to help people perform automatic keywords extraction have been proposed. Conditional Random Fields (CRF) model is a state-of-the-art sequence labeling method, which can use the features of documents more sufficiently and effectively. At the same time, keywords extraction can be considered as the string labeling. In this paper, keywords extraction based on CRF is proposed and implemented. As far as we know, using CRF model in keyword extraction has not been investigated previously. Experimental results show that the CRF model outperforms other machine learning methods such as support vector machine, multiple linear regression model etc. in the task of keywords extraction.},
annote = {Good ideas for SVs lol},
author = {Zhang, Chengzhi and Wang, Huilin and , Yao and Wu, Dan and Liao, Yi and Wang, Bo},
file = {:C$\backslash$:/Users/Tom/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2008 - Automatic Keyword Extraction from Documents Using Conditional Random Fields.pdf:pdf},
issn = {15539105},
journal = {Journal of Computational Information},
keywords = {Automatic Indexing,Conditional Random Fields,Extraction,Machine Learning},
pages = {1169--1180},
title = {{Automatic Keyword Extraction from Documents Using Conditional Random Fields}},
url = {http://www.jofci.org},
volume = {43},
year = {2008}
}
@article{Chih-WeiHsuChih-ChungChang2008,
abstract = {The support vector machine (SVM) is a popular classi cation technique. However, beginners who are not familiar with SVM often get unsatisfactory results since they miss some easy but signi cant steps. In this guide, we propose a simple procedure which usually gives reasonable results. developed well-differentiated superficial transitional cell bladder cancer. CONCLUSIONS: Patients with SCI often prefer SPC than other methods offered to them, because of quality-of-life issues. The incidence of significant complications might not be as high as previously reported, and with a commitment to careful follow-up, SPC can be a safe option for carefully selected patients if adequate surveillance can be ensured.},
annote = {libsvm},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {{Chih-Wei Hsu, Chih-Chung Chang}, and Chih-Jen Lin},
doi = {10.1177/02632760022050997},
eprint = {0-387-31073-8},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/libsvm-guide.pdf:pdf},
isbn = {013805326X},
issn = {1464-410X},
journal = {BJU international},
number = {1},
pages = {1396--400},
pmid = {18190633},
title = {{A Practical Guide to Support Vector Classification}},
url = {http://www.csie.ntu.edu.tw/{~}cjlin/papers/guide/guide.pdf},
volume = {101},
year = {2008}
}
@misc{Winters-Hilt2007,
abstract = {BACKGROUND: Support Vector Machines (SVMs) provide a powerful method for classification (supervised learning). Use of SVMs for clustering (unsupervised learning) is now being considered in a number of different ways.$\backslash$n$\backslash$nRESULTS: An SVM-based clustering algorithm is introduced that clusters data with no a priori knowledge of input classes. The algorithm initializes by first running a binary SVM classifier against a data set with each vector in the set randomly labelled, this is repeated until an initial convergence occurs. Once this initialization step is complete, the SVM confidence parameters for classification on each of the training instances can be accessed. The lowest confidence data (e.g., the worst of the mislabelled data) then has its' labels switched to the other class label. The SVM is then re-run on the data set (with partly re-labelled data) and is guaranteed to converge in this situation since it converged previously, and now it has fewer data points to carry with mislabelling penalties. This approach appears to limit exposure to the local minima traps that can occur with other approaches. Thus, the algorithm then improves on its weakly convergent result by SVM re-training after each re-labeling on the worst of the misclassified vectors - i.e., those feature vectors with confidence factor values beyond some threshold. The repetition of the above process improves the accuracy, here a measure of separability, until there are no misclassifications. Variations on this type of clustering approach are shown.$\backslash$n$\backslash$nCONCLUSION: Non-parametric SVM-based clustering methods may allow for much improved performance over parametric approaches, particularly if they can be designed to inherit the strengths of their supervised SVM counterparts.},
author = {Winters-Hilt, Stephen and Merat, Sam},
booktitle = {BMC Bioinformatics},
doi = {10.1186/1471-2105-8-S7-S18},
isbn = {1471-2105 (Electronic)},
issn = {14712105},
number = {Suppl 7},
pages = {S18},
pmid = {18047717},
title = {{SVM clustering}},
url = {http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-S7-S18},
urldate = {2017-10-19},
volume = {8},
year = {2007}
}
@article{Snow2013,
abstract = {Semantic taxonomies such as WordNet provide a rich source of knowl- edge for natural language processing applications, but are expensive to build, maintain, and extend. Motivated by the problem of automatically constructing and extending such taxonomies, in this paper we present a new algorithm for automatically learning hypernym (is-a) relations from text. Our method generalizes earlier work that had relied on using small numbers of hand-crafted regular expression patterns to identify hyper- nym pairs. Using “dependency path” features extracted from parse trees, we introduce a general-purpose formalization and generalization of these patterns. Given a training set of text containing known hypernym pairs, our algorithm automatically extracts useful dependency paths and applies them to new corpora to identify novel pairs. On our evaluation task (de- termining whether two nouns in a news article participate in a hypernym relationship), our automatically extracted database of hypernyms attains both higher precision and higher recall thanWordNet.},
annote = {{\textperiodcentered} Can do better than just WordNet classifiers},
author = {Snow, Rion and Jurafsky, Daniel and {Y. Ng}, Andrew},
doi = {10.1136/amiajnl-2011-000376},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/Learning syntactic patterns for automatic.pdf:pdf},
isbn = {0262195348},
issn = {1096-0260},
journal = {Journal of the American Medical Informatics Association},
keywords = {Adolescent,Adult,Adverse Drug Reaction Reporting Systems,Attitude to Health,Attitudes,Autistic Disorder,Big data,Blogging,Centers for Disease Control and Prevention (U.S.),Chi-Square Distribution,Clinical Coding,Communicable Diseases,Computer Systems,Controlled,Cross-Sectional Studies,Cultural Characteristics,Data Collection,Data Mini,Data Mining,Databases,Digital epidemiology,Dis,Disease Outbreaks,Drug Interactions,Drug-Related Side,Electronic Health Records,Epidemiologic Methods,Epidemiology,Factual,Female,HIV,HIV detection,HIV prevention,Health Behavior,Health Education,Health Education: statistics {\&} numerical data,Health Knowledge,Health Services Research,Human,Human: diagnosis,Human: epidemiology,Human: transmission,Human: virology,Humans,Hyperglycemia,Immunization,Immunization Programs,Influenza,Information Storage and Retri,Inte,Intern,Internationality,Internet,Internet: utilization,Linear Models,Longitudinal Studies,MEDLINE,Male,Mass Media,MedDRA,Middle Aged,Models,Natural Language Processing,OWL,Observation,Office Visits,Office Visits: statistics {\&} numerical data,Papillomavirus Infections,Papillomavirus Vaccines,Paroxeti,Patient A,Patient Acceptance of Health Care,Pharmaceutical,Pharmacovigilance,Poliovirus Vaccines,Politics,Population Surveillance,Population Surveillance: methods,Postmarketing,Practice,Pravastatin,Preservatives,Prevention,Product Surveillance,Public Health,Public Opinion,Questionnaires,ROC Curve,Reproducibility of Results,Reproductive,Risk,Safety,Seasons,Sem,Semantics,Serotonin Uptake Inhibitors,Sexually Transmitted Diseases,Social Media,Social media,Social networking,Socioeconom,Surveillance,Terminology as Topic,Tetanus Toxoid,Theoretical,Thimerosal,Time Factors,Trust,Twitter,United States,User-Computer Interface,Uterine Cervical Neoplasms,Uterine Cervical Neoplasms: prevention {\&} control,Uterine Cervical Neoplasms: virology,Vaccination,Vaccines,Viral,Viral: prevention {\&},Viral: virology,Vocabulary,World,administration /{\&}/ dosage,administration /{\&}/ dosage/adverse effects,administration /{\&}/ dosage/adverse effects/immunol,adverse effects,adverse effects/methods/psychology,chemically induced,datamining,epidemiology,hepatitis B,hib,immunology,methods,ontology,organization /{\&}/ administration/standards,pentavalent,prevention /{\&}/ control,psychology/utilization,semantic groups,standards,statistics /{\&}/ numerical data,support,terminology clustering,trends,umls,utilization,vaccine},
number = {1},
pages = {1--11},
pmid = {25720841},
title = {{Learning syntactic patterns for automatic hypernym discovery}},
url = {http://dx.doi.org/10.1186/s12859-015-0606-0{\%}5Cnhttp://dx.doi.org/10.1016/j.jbi.2015.02.004{\%}5Cnhttp://dx.doi.org/10.1371/journal.pcbi.1002199{\%}5Cnhttp://onlinelibrary.wiley.com/doi/10.1002/pds.3838/abstract{\%}5Cnhttp://jamia.oxfordjournals.org/content/17/6/65},
volume = {20},
year = {2013}
}
@article{Liu2009,
abstract = {Keyphrases are widely used as a brief summary of documents. Since manual assignment is time-consuming, various unsupervised ranking methods based on importance scores are proposed for keyphrase extraction. In practice, the keyphrases of a document should not only be statistically important in the document, but also have a good coverage of the document. Based on this observation, we propose an unsupervised method for keyphrase extraction. Firstly, the method finds exemplar terms by leveraging clustering techniques, which guarantees the document to be semantically covered by these exemplar terms. Then the keyphrases are extracted from the document using the exemplar terms. Our method outperforms sate-of-the-art graph-based ranking methods (TextRank) by 9.5{\%} in F1-measure.},
annote = {{\textperiodcentered}        Unsupervised (so it doesn't need a human annotated training set) 
{\textperiodcentered}        Good key phrases should be understandable, relevant and good coverage (cover whole document) 
{\textperiodcentered}        Suggest: unsupervised clustering-based method 
o   Cluster based on semantic relation 
o   Center in exemplar term – key phrase! 
o   Candidate words selected with heuristic 
{\textperiodcentered}        Language independent 
{\textperiodcentered}        Section 2 – related work 
{\textperiodcentered}        5.2 – this method applied to actual papers? 
{\textperiodcentered}        “In this paper, we use three widely used clustering algorithms, hierarchical clustering, spectral clustering and Affinity Propagation [low error],” 
o   Clustering seems like a good idea 
{\textperiodcentered}        See future work, as decent notes for investigation here},
author = {Liu, Zhiyuan and Li, Peng and Zheng, Yabin and Sun, Maosong},
doi = {10.3115/1699510.1699544},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/p257-liu.pdf:pdf},
isbn = {9781932432596},
journal = {Language},
pages = {257--266},
title = {{Clustering to Find Exemplar Terms for Keyphrase Extraction}},
url = {http://portal.acm.org/citation.cfm?doid=1699510.1699544},
volume = {1},
year = {2009}
}
@article{Augenstein2017,
abstract = {We describe the SemEval task of extracting keyphrases and relations between them from scientific documents, which is crucial for understanding which publications describe which processes, tasks and materials. Although this was a new task, we had a total of 26 submissions across 3 evaluation scenarios. We expect the task and the findings reported in this paper to be relevant for researchers working on understanding scientific content, as well as the broader knowledge base population and information extraction communities.},
annote = {{\textperiodcentered}        Corpus build from ScienceDirect open access publications 
o   Each data instance consists of one paragraph of text 
{\textperiodcentered}        22{\%} of all key phrases in training set were words of length 5+ 
{\textperiodcentered}        93{\%} of key phrases are noun phrases (helps heuristic to find likely candidates) 
{\textperiodcentered}        31{\%} only appear once, so generalisation needed for unseen key phrases! 
{\textperiodcentered}        Only mark paragraphs likely to have relations 
{\textperiodcentered}        They paid students to annotate paragraphs selected by the system 
{\textperiodcentered}        Should look at Sonal Gupta and Christopher Manning. 2011. Analyzing the Dynamics of Research by Extracting Key Aspects of Scientific Papers. In Proceedings of IJCNLP. 
{\textperiodcentered}        Other teams TTI{\_}COIN, TAIL{\_}UW and s2{\_}end2end (F1 = 0.38, 0.42, 0.43) used recurrent neural network (RNN). The 2nd two used CRF layer on top of RNNS to achieve a higher F1 in subtask A 
{\textperiodcentered}        Other decent results (F1 {\~{}} 0.25) used SVM classifier on provided training data to classify phrases and used a CRF to predict labels of the phrases. 
{\textperiodcentered}        Task 3 had RNN  based approaches working well (up to F1 0.6) 
{\textperiodcentered}        Generally, it's best to use RNNs, in combination with CRFs 
o   Best was a SVM with a well-engineered lexical feature set however 
{\textperiodcentered}        Identifying the key phrases was the hardest part},
archivePrefix = {arXiv},
arxivId = {1704.02853},
author = {Augenstein, Isabelle and Das, Mrinal and Riedel, Sebastian and Vikraman, Lakshmi and McCallum, Andrew},
eprint = {1704.02853},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/SemEval 2017 Task 10 ScienceIE Extracting Keyphrases and Relations from Scientific Publications.pdf:pdf},
pages = {546--555},
title = {{SemEval 2017 Task 10: ScienceIE - Extracting Keyphrases and Relations from Scientific Publications}},
url = {http://arxiv.org/abs/1704.02853},
year = {2017}
}
@article{Ammar2017,
abstract = {This paper describes our submission for$\backslash$nthe ScienceIE shared task (SemEval-$\backslash$n2017 Task 10) on entity and relation$\backslash$nextraction from scientific papers. Our$\backslash$nmodel is based on the end-to-end relation$\backslash$nextraction model of Miwa and Bansal$\backslash$n(2016) with several enhancements such as$\backslash$nsemi-supervised learning via neural language$\backslash$nmodels, character-level encoding,$\backslash$ngazetteers extracted from existing knowledge$\backslash$nbases, and model ensembles. Our of-$\backslash$nficial submission ranked first in end-to-end$\backslash$nentity and relation extraction (scenario 1),$\backslash$nand second in the relation-only extraction$\backslash$n(scenario 3).},
annote = {{\textperiodcentered}        “Our model is based on the end-to-end relation extraction model of Miwa and Bansal (2016) with several enhancements such as semi-supervised learning via neural language models, character-level encoding, gazetteers extracted from existing knowledge bases, and model ensembles.” 
{\textperiodcentered}        Text processing -{\textgreater} Spacy again (sentence segmentation, tokenization, part of speech tagging and labelled dependency parsing) 
{\textperiodcentered}        Label encoding -{\textgreater} BILOU tagging 
{\textperiodcentered}        Hyponym-of is directional relation, synonym-of is unidirectional relation 
{\textperiodcentered}        Hyponym-of(e2, e1) automatically makes hypernym-of(e1, e2) 
{\textperiodcentered}        Use LSTMs followed by CRF for sequence tagging model 
{\textperiodcentered}        Gazetteers - Used scientific terms from web and several topics from freebase and added them as features in the sequence tagging model 
{\textperiodcentered}        Joining models before training adds some practical complexities, but may result in better results 
{\textperiodcentered}        This paper scores 1st in end-to-end, but 2nd for just task 2},
author = {Ammar, Waleed and Peters, Matthew and Bhagavatula, Chandra and Power, Russell},
doi = {10.18653/V1/S17-2097},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/The AI2 system at SemEval-2017 Task 10 (ScienceIE) semi-supervised end-to-end entity and relation extraction.pdf:pdf},
journal = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
pages = {592--596},
title = {{The AI2 system at SemEval-2017 Task 10 (ScienceIE): semi-supervised end-to-end entity and relation extraction}},
url = {http://www.aclweb.org/anthology/S17-2097},
volume = {10},
year = {2017}
}
@article{Marsi2017,
abstract = {We present NTNU's systems for Task A (prediction of keyphrases) and Task B$\backslash$n(labelling as Material, Process or Task) at SemEval 2017 Task 10: Extracting$\backslash$nKeyphrases and Relations from Scientific Publications$\backslash$n$\backslash$cite{\{}augenstein2017scienceie{\}}. Our approach relies on supervised machine$\backslash$nlearning using Conditional Random Fields. Our system yields a micro F-score of$\backslash$n0.34 for Tasks A and B combined on the test data. For Task C (relation$\backslash$nextraction), we relied on an independently developed system described in$\backslash$n$\backslash$cite{\{}Barik:2017{\}}. For the full Scenario 1 (including relations), our approach$\backslash$nreaches a micro F-score of 0.33 (5th place). Here we describe our systems,$\backslash$nreport results and discuss errors.},
annote = {{\textperiodcentered}        Only task a and b. 
{\textperiodcentered}        F-score of 0.34 
{\textperiodcentered}        Conditional Random Fields 
{\textperiodcentered}        Pre-processing – Spacy NLP pipeline (sentence splitting, lemmatisation and dependency parsing 
{\textperiodcentered}        Uses IOB tags 
{\textperiodcentered}        If material (e.g. ‘carbon') was found in some places, all other occurrences were marked the same later 
{\textperiodcentered}        Good idea of how to do classification 
o   Could use word net? 
o   Could use some classification tools for syn of (abbreviation, similarity) 
{\textperiodcentered}        Slightly different classifiers for task, process and material 
{\textperiodcentered}        Wrote 2 systems (2 was thought to be better) so when making system 3, both were used but 2 was preferred. 
{\textperiodcentered}        Generally best at material and worst at task (task was least common in training data) 
{\textperiodcentered}        Models made overfitted on dev/test data 
{\textperiodcentered}        Lots of errors in relationship extraction, as errors in key phrase extraction propagate 
{\textperiodcentered}        Spacy made errors with periods a lot (miss aligning key phrases)},
author = {Marsi, Erwin and Sikdar, Utpal Kumar and Marco, Cristina and Barik, Biswanath and S{\ae}tre, Rune},
doi = {10.18653/V1/S17-2162},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/ScienceIE at SemEval-2017 Task 10 Identifying and Labelling Keyphrases with Conditional Random Fields.pdf:pdf},
journal = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
pages = {937--940},
title = {{NTNU-1{\$}@{\$}ScienceIE at SemEval-2017 Task 10: Identifying and Labelling Keyphrases with Conditional Random Fields}},
url = {http://www.aclweb.org/anthology/S17-2162},
year = {2017}
}
@article{Gupta2011,
abstract = {We present a method for characterizing a research work in terms of its focus, do- main of application, and techniques used. We show how tracing these aspects over time provides a novel measure of the in- fluence of research communities on each other. We extract these characteristics by matching semantic extraction patterns, learned using bootstrapping, to the depen- dency trees of sentences in an article's abstract. We combine this information with pre-calculated article-to-community assignments to study the influence of a community on others in terms of tech- niques borrowed and the ‘maturing' of some communities to solve other prob- lems. As a case study, we show how the computational linguistics community and its sub-fields have changed over the years with respect to their foci, methods used, and domain problems. For instance, we show that part-of-speech tagging and parsing have increasingly been adopted as tools for solving problems in other do- mains. We also observe that speech recog- nition and probability theory have had the most seminal influence.},
annote = {{\textperiodcentered}        Used dependency trees 
{\textperiodcentered}        We extract the phrase corresponding to the matched phrase-tree and label it with the pattern's category. For example, the dependency tree in Figure 1 matches the FOCUS pattern [work -{\textgreater} (preposition on)] and the TECHNIQUE pattern [using -{\textgreater} (direct-object)].},
author = {Gupta, Sonal and Manning, Christopher},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/gupta-manning-ijcnlp11.pdf:pdf},
journal = {Proceedings of 5th International Joint Conference on Natural Language Processing},
pages = {1--9},
title = {{Analyzing the Dynamics of Research by Extracting Key Aspects of Scientific Papers}},
url = {papers2://publication/uuid/6492A1E9-C692-49B8-A9C6-AAFEE4309A5C},
year = {2011}
}
@article{Hasan2014,
abstract = {While automatic keyphrase extraction has been examined extensively, state-of-the- art performance on this task is still much lower than that on many core natural lan- guage processing tasks. We present a sur- vey of the state of the art in automatic keyphrase extraction, examining the major sources of errors made by existing systems and discussing the challenges ahead.},
annote = {{\textperiodcentered}        Task gets harder the longer the doc as more candidates (papers are long{\ldots}) 
{\textperiodcentered}        “a scientific paper typically has at least 10 keyphrases and hundreds of candidate keyphrases, yielding a much bigger search space” 
{\textperiodcentered}        Many of the publicly available corpora can be found in http://github.com/snkim/AutomaticKeyphraseExtraction/ and http://code.google.com/p/maui-indexer/downloads/list . 
{\textperiodcentered}        Usually, approaches are 
1.      Select candidate keyphrases with heuristic 
2.      Determine using either 
{\S}  Unsupervised learning 
{\S}  Supervised learning 
{\textperiodcentered}        Section 3.(1, 2, 3) describes the above note 
o   3.1 may experiment with different approaches 
{\textperiodcentered}        Supervised learning 
o   Generate positive and negative examples 
{\textperiodcentered}        Unsupervised approaches 
o   Graph based approaches 
o   Clustering 
{\S}  Eg clusters semantically similar candidate using Wikipedia and co-occurrence-based statistics 
{\S}  Consider importance of topics/clusters (do all need a key phrase representation?) 
o   LMA scores a candidate keyphrase based on two features, namely, phraseness (i.e., the extent to which a word sequence can be treated as a phrase) and informativeness (i.e., the extent to which a word sequence captures the central idea of the document it appears in). Intuitively, a phrase that has high scores for phraseness and informativeness is likely to be a keyphrase. 
{\textperiodcentered}        “not observe any significant difference between the types of errors made by the four systems other than the fact that the supervised system has the expected tendency to predict keyphrases seen in the training data.” 
{\textperiodcentered}        Errors: 
o   Overgeneration (28-37{\%} of errors) 
{\S}  Picks a keyword, but also other words as they contain the key words 
o   Infrequency errors 
{\S}  Key phrase is so infrequent, it isn't selected 
o   Redundancy errors 
{\S}  Outputting alias of key phrases + key phrase 
o   Evaluation errors 
{\S}  Problems with evaluation programs 
{\textperiodcentered}        Recommendations: 
o   See section 5.2 
{\textperiodcentered}        Similarity is often gained through co-occurrence information 
{\textperiodcentered}        Three major challenges: 
o   Incorporating background knowledge 
o   Handling long documents 
o   Improving evaluation schemes




BLEU,METEOR, NIST, and ROUGE for use in evaluation},
author = {Hasan, Kazi Saidul and Ng, Vincent},
doi = {10.3115/v1/P14-1119},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/Automatic Keyphrase Extraction A Survey of the State of the Art.pdf:pdf},
isbn = {9781937284725},
journal = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
pages = {1262--1273},
title = {{Automatic Keyphrase Extraction: A Survey of the State of the Art}},
url = {http://aclweb.org/anthology/P14-1119},
year = {2014}
}
@article{Baker1998,
abstract = {This paper describes the application of Dis? tributional Clustering ???? to documen t classi?cation? This approac h clusters w ords in to groups based on the distribution of class labels associated with eac h w ord? Th us? unlik e some other unsupervised dimensionalit y? reduction tec hniques? suc h as Laten t Seman tic Indexing? w e are able to compress the feature space m h more uc aggressiv ely ? while still main taining high documen tclas? si?cation accuracy ? Experimen tal results obtained on three real?w orld data sets sho w that w e can reduce the feature dimen? sionalit yb y three orders of magnitude and lose only ?? accuracy?signi?can tly better than Laten t Seman tic In? dexing ???? class?based clustering ???? feature selection b y m utual information ????? or Mark v?blank o et?based fea? ture selection ????? W e also sho w that less aggressiv e clustering sometimes results in impro ed classi?cation v accuracy o er classi?cation without clustering? v ?},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Baker, L. Douglas and McCallum, Andrew Kachites},
doi = {10.1145/290941.290970},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/Distributional Clustering of Words for Text Classication.pdf:pdf},
isbn = {1581130155},
issn = {1098-6596},
journal = {Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval - SIGIR '98},
pages = {96--103},
pmid = {25246403},
title = {{Distributional clustering of words for text classification}},
url = {http://portal.acm.org/citation.cfm?doid=290941.290970},
year = {1998}
}
@article{Wu2005,
abstract = {Keyphrases are an important means of document summarization, clustering, and topic search. Only a small minority of documents have author-assigned keyphrases, and manually assigning keyphrases to existing documents is very laborious. Therefore it is highly desirable to automate the keyphrase extraction process. This paper shows that a simple procedure for keyphrase extraction based on the naive Bayes learning scheme performs comparably to the state of the art. It goes on to explain how this procedure's performance can be boosted by automatically tailoring the extraction process to the particular document collection at hand. Results on a large collection of technical reports in computer science show that the qualit y of the extracted keyphrases improves significantly when domain-specific information is exploited.},
annote = {{\textperiodcentered}        Can cluster documents on key phrases as they summarize concisely. Low-cost. 
{\textperiodcentered}        Machine learning is interesting. 
{\textperiodcentered}        Two approaches: key phrase assignment and extraction (perused in this paper) 
{\textperiodcentered}        Extraction: 
o   No restriction through vocabulary 
o   Use machine learning on set of training documents 
o   Machine learning requires lots of training data 
{\textperiodcentered}        Only useful properties of key phrases seemed useful: TF X IDF (calculation explained in 2.2) score of a phrase, and the distance into the document of the phrase's first appearance (number of words before it / total words in document). 
{\textperiodcentered}        Na{\"{i}}ve Bayes learning method can process numeric attributes by assuming a normal distribution. 
o   They discretised their results which showed normal dist. Not appropriate in this application 
{\S}  Explained in 2.2 
{\textperiodcentered}        Na{\"{i}}ve Bayes here assumes attributes (the two above) are independent given the class. Results in ￼ 
{\textperiodcentered}        Na{\"{i}}ve Bayes can be accurate, even if independence assumption isn't correct 
{\textperiodcentered}        Used 55 author annotated articles 
{\textperiodcentered}        GenEx performed well 
{\textperiodcentered}        Increasing training docs above 50 didn't seem improve performance 
{\textperiodcentered}        Optimum is 50 
{\textperiodcentered}        The more author assigned papers, the better 
{\textperiodcentered}        “Making use of knowledge about which key phrases are used frequently in a particular domain has the additional advantage that the extracted key phrases are more uniform. This property makes it easier to categorize documents using the key phrases extracted, and should be beneficial if they are used for topic search”},
author = {Wu, Yi-fang Brook and Li, Quanzhi and Bot, Razvan Stefan and Chen, Xin},
doi = {10.1145/1099554.1099628},
file = {:C$\backslash$:/Users/Tom/OneDrive/University/Yr3/FYP/Papers/domain-specific keyphrase extraction.pdf:pdf},
isbn = {1595931406},
journal = {Proceedings of the 14th ACM international conference on Information and knowledge management  - CIKM '05},
pages = {283},
title = {{Domain-specific keyphrase extraction}},
url = {http://portal.acm.org/citation.cfm?doid=1099554.1099628},
year = {2005}
}
